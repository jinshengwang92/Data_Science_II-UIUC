{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 6 Problem 3\n",
    "\n",
    "If you are not using the `Assignments` tab on the course JupyterHub server to read this notebook, read [Activating the assignments tab](https://github.com/lcdm-uiuc/info490-sp17/blob/master/help/act_assign_tab.md).\n",
    "\n",
    "A few things you should keep in mind when working on assignments:\n",
    "\n",
    "1. Make sure you fill in any place that says `YOUR CODE HERE`. Do **not** write your answer in anywhere else other than where it says `YOUR CODE HERE`. Anything you write anywhere else will be removed or overwritten by the autograder.\n",
    "\n",
    "2. Before you submit your assignment, make sure everything runs as expected. Go to menubar, select _Kernel_, and restart the kernel and run all cells (_Restart & Run all_).\n",
    "\n",
    "3. Do not change the title (i.e. file name) of this notebook.\n",
    "\n",
    "4. Make sure that you save your work (in the menubar, select _File_  â†’ _Save and CheckPoint_)\n",
    "\n",
    "5. You are allowed to submit an assignment multiple times, but only the most recent submission will be graded.\n",
    "-----\n",
    "# Problem 6.3. Practical Concepts\n",
    "\n",
    "In this problem, we explore a number of practical concepts that can be very important in real-world machine learning applications. These concepts include\n",
    "\n",
    "- Feature Scaling\n",
    "- Feature Selection\n",
    "- Pipelining\n",
    "- Cross Validation\n",
    "- Grid Search\n",
    "- Validation/Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "b6e96ee95c920796458f88e6d3bb9be8",
     "grade": false,
     "grade_id": "import",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\")\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "from sklearn import cross_validation as cv\n",
    "from sklearn.feature_selection import RFE, SelectKBest, f_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.learning_curve import validation_curve\n",
    "\n",
    "from nose.tools import assert_equal, assert_is_instance, assert_is_not\n",
    "from numpy.testing import assert_array_equal, assert_array_almost_equal, assert_almost_equal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset we're going to handle is a collection of shape and texture features extracted from digital images of leaf specimens orginating from a total of about 40 different plant species. The csv data file has 16 columns and we could drop out the second column, `Specimen Number`, because it is not relevant to classification. The integers in `Class (Species)` represent leaves of different classes/species as in the following image:\n",
    "![](./images/leaf.png)\n",
    "We'll use `Class (Species)` as classes, and the rest 15 columns as features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "8a2477672ab2f88616dd1b191763d307",
     "grade": false,
     "grade_id": "data",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# data from https://archive.ics.uci.edu/ml/datasets/Leaf\n",
    "file = '/home/data_scientist/data/misc/leaf.csv'\n",
    "leaves = pd.read_csv(file, names=['Class (Species)', 'Specimen Number', 'Eccentricity', 'Aspect Ratio',\n",
    "                                  'Elongation', 'Solidity', 'Stochastic Convexity', 'Isoperimetric Factor', \n",
    "                                  'Maximal Indentation Depth', 'Lobedness', 'Average Intensity', \n",
    "                                  'Average Contrast', 'Smoothness', 'Third Moment', 'Uniformity', 'Entropy'])\n",
    "\n",
    "leaves = leaves.drop('Specimen Number', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "e65b655383c9f71a1c5e2a8dd0240dd0",
     "grade": false,
     "grade_id": "head",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "print(leaves.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "d541f2bb1204c2432244665b49c04d0f",
     "grade": false,
     "grade_id": "features_n_classes",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "f = leaves.drop('Class (Species)', axis=1) # features\n",
    "c = leaves['Class (Species)'] # classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling\n",
    "\n",
    "We have explored feature scaling in [Problem 5.1](../Week5/Assignments/w5p1.ipynb), so I'll do this for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "9505c7155a067e5bbbf8f88b63825ade",
     "grade": false,
     "grade_id": "scaling",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "f_scaled = pd.DataFrame(preprocessing.StandardScaler().fit_transform(f), columns=f.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "Now we'll try to do feature selection using both [Recursive Feature Elimination (RFE)](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html) and [Random Forest Classifier (RFC)](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html). \n",
    "\n",
    "In the following cell, use [Recursive Feature Elimination](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html) to determine the most important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "10ca1b82559b586ac0d255b00715a7b8",
     "grade": false,
     "grade_id": "rfe_selection",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def select_features_rfe(X, y, random_state, kernel='linear', C=1.0, num_attributes=3):\n",
    "    '''\n",
    "    Uses Support Vector Classifier as the estimator to rank features\n",
    "    with Recursive Feature Elimination.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X: A pandas.DataFrame. Features.\n",
    "    y: A pandas.DataFrame. Classes.\n",
    "    random_state: A RandomState instance. Used in SVC().\n",
    "    kernel: A string. Used in SVC(). Default: \"linear\".\n",
    "    C: A float. Used in SVC(). Default: 1.0.\n",
    "    num_attributes: An int. The number of features to select in RFE. Default: 3.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A 3-tuple of (RFE, np.ndarray, np.ndarray)\n",
    "    rfe: An RFE instance.\n",
    "    columns: Selected column names. A numpy array of strings.\n",
    "    ranking: The feature ranking. Selected features are assigned rank 1. A numpy array of integers.\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return rfe, columns, ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "7bf57eb439198f00766bc3c76d0f56b2",
     "grade": false,
     "grade_id": "rfe_execute",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "t_rfe, t_columns, t_ranking = select_features_rfe(f_scaled, c, check_random_state(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "9b5f81f6e6859c6f9ebfd99ea7917363",
     "grade": true,
     "grade_id": "rfe_test",
     "locked": true,
     "points": 9,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_instance(t_rfe, RFE)\n",
    "assert_is_instance(t_ranking, np.ndarray)\n",
    "\n",
    "assert_is_instance(t_rfe.estimator, svm.SVC)\n",
    "assert_equal(t_rfe.estimator.kernel, 'linear')\n",
    "assert_equal(t_rfe.estimator.C, 1)\n",
    "assert_equal(t_rfe.n_features_, 3)\n",
    "\n",
    "assert_array_equal(t_columns, ['Eccentricity', 'Isoperimetric Factor', 'Average Contrast'])\n",
    "assert_array_equal(t_ranking, [1, 8, 2, 5, 10, 1, 3, 12, 11, 1, 9, 7, 6, 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, use [Random Forest Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) to determine the most important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "7b5456aec0398b65816ea40f3a7d3789",
     "grade": false,
     "grade_id": "rfc_select",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def select_features_rfc(X, y, random_state, n_estimators=10, n_selected_columns=3):\n",
    "    '''\n",
    "    Uses Random Forest Classifier as the estimator to rank features.\n",
    "    Sorts feature columns based on importances, and returns\n",
    "    specified number of column names with highest importances.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X: A pandas.DataFrame. Features.\n",
    "    y: A pandas.DataFrame. Classes.\n",
    "    random_state: A RandomState instance. Used in RandomForestClassifier().\n",
    "    n_estimator: A float. Used in RandomForestClassifier(). Default: 10.\n",
    "    n_selected_columns: An int. The number of features/columns to select. Default: 3.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A 3-tuple of (RFC, np.ndarray, np.ndarray)\n",
    "    rfc: An RFC instance.\n",
    "    columns: Selected column names. A numpy array of strings.\n",
    "    importance: The feature importances. A numpy array of floats.\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return rfc, columns, importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "fd019f6b9dbd63a6dd04962395b22b7a",
     "grade": false,
     "grade_id": "rfc_execute",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "u_rfc, u_columns, u_importance = select_features_rfc(f_scaled, c, check_random_state(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "5ae254221a8f0be454fd70dcec9d7f6b",
     "grade": true,
     "grade_id": "rfc_test",
     "locked": true,
     "points": 9,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_instance(u_rfc, RandomForestClassifier)\n",
    "assert_is_instance(u_importance, np.ndarray)\n",
    "\n",
    "assert_array_equal(u_columns, ['Eccentricity', 'Solidity', 'Entropy'])\n",
    "assert_array_almost_equal(u_importance, \n",
    "                          [ 0.1004033 ,  0.0796833 ,  0.08358279,  0.09997119,  0.06706054,\n",
    "                            0.08678733,  0.05865014,  0.07139296,  0.04943292,  0.04209375,\n",
    "                            0.06102167,  0.04721591,  0.06452248,  0.08818172])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Anova RFC\n",
    "Construct a pipeline that selects the `k` best features from a data set using an ANOVA filter (see [SelectKBest](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html)), and then employs a Random Forest Classification. Use [ANOVA F-value](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_classif.html#sklearn.feature_selection.f_classif) for the score function. Name the pipe elements \"anova\" and \"rfc\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "b375eb0bcbaa321483a515f35ef80c58",
     "grade": false,
     "grade_id": "pipeline",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def anova_rfc_pipeline(X, y, random_state, k=3, n_estimators=10, max_depth=4):\n",
    "    '''\n",
    "    Selects top k features with a pipeline that uses ANOVA F-value\n",
    "    and a Random Forest Classifier.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X: A pandas.DataFrame. Features.\n",
    "    y: A pandas.DataFrame. Classes.\n",
    "    random_state: A RandomState instance. Used in RandomForestClassifier().\n",
    "    k: An int. The number of features to select. Default: 3.\n",
    "    n_estimators: A float. Used by RandomForestClassifier(). Default: 10.\n",
    "    max_depth: A float. Used by RandomForestClassifier(). Default: 4.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A 2-tuple of (Pipeline, np.ndarray)\n",
    "    model: An ANOVA RFC pipeline.\n",
    "    predictions: Classifications predicted by the pipeline.\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return model, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "3435b9480af61862b24a1c339ca3def2",
     "grade": false,
     "grade_id": "pipeline_execute",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "t_model, t_pred = anova_rfc_pipeline(f_scaled, c, random_state=check_random_state(0), n_estimators=30, max_depth=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "ada9fc082ed6a2cea3ade25e74fd4da7",
     "grade": true,
     "grade_id": "pipeline_test",
     "locked": true,
     "points": 9,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_instance(t_model, Pipeline)\n",
    "assert_equal(t_model.steps[0][0], 'anova')\n",
    "assert_equal(t_model.steps[1][0], 'rfc')\n",
    "assert_equal(t_model.get_params()['anova__k'], 3)\n",
    "assert_equal(t_model.get_params()['rfc__n_estimators'], 30)\n",
    "assert_equal(t_model.get_params()['rfc__max_depth'], 6)\n",
    "\n",
    "assert_is_instance(t_pred, np.ndarray)\n",
    "assert_equal(len(t_pred), 340)\n",
    "assert_array_equal(t_pred[:15], [13,  1,  1,  1,  1, 13,  1,  1,  1, 14, 13,  1,  2,  2,  2])\n",
    "assert_array_equal(t_pred[-15:], [35, 35, 35, 35, 12, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search\n",
    "\n",
    "Use a [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.GridSearchCV.html) object to compute the best value for the `max_depth` parameter when running the RFC algorithm. You may want to refer to [Problem 4.3](../Week4/assignments/w4p3.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "412b2dbd00e6fe9b27d3cba860875b88",
     "grade": false,
     "grade_id": "grid",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def find_best_max_depth(X, y, split_random_state, rfc_random_state, max_depth_values, test_size=0.2, n_estimators=10):\n",
    "    '''\n",
    "    Do a grid search to find the optimized max_depth parameter.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X: A pandas.DataFrame. Features.\n",
    "    y: A pandas.DataFrame. Classes.\n",
    "    split_random_state: A RandomState instance. Used in train_test_split().\n",
    "    rfc_random_state: A RandomState instance. Used in RandomForestClassifier().\n",
    "    max_depth_values: A np.array. A list of parameter settings to try as max_depth.\n",
    "    test_size: A float. Used in train_test_split(). Default: 0.2.\n",
    "    n_estimators: A float. Used by RandomForestEstimator(). Default: 10.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A 3-tuple of (GridSearchCV, float, float)\n",
    "    model: A GridSearchCV instance.\n",
    "    best_max_depth: The value of max_depth that gave the highest score.\n",
    "    best_cv_score: Score of best_max_depth on the hold out data.\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return model, best_max_depth, best_cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "4df5e83aad7dd85b52545be6137da990",
     "grade": true,
     "grade_id": "grid_test",
     "locked": true,
     "points": 7,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "f_selected = f_scaled[t_columns] # use columns selected by RFE\n",
    "\n",
    "model1, max_depth1, score1 = find_best_max_depth(f_selected, c, check_random_state(0), check_random_state(1), \n",
    "                                                 np.arange(1,12), test_size=0.3, n_estimators=20)\n",
    "assert_is_instance(model1, GridSearchCV)\n",
    "assert_is_instance(model1.estimator, RandomForestClassifier)\n",
    "assert_equal(model1.estimator.n_estimators, 20)\n",
    "assert_array_equal(model1.param_grid['max_depth'], np.arange(1,12))\n",
    "assert_equal(max_depth1, 7)\n",
    "assert_almost_equal(score1, 0.52941176470588236)\n",
    "\n",
    "model2, max_depth2, score2 = find_best_max_depth(f_selected, c, check_random_state(2), check_random_state(2), \n",
    "                                                 np.arange(1,12), test_size=0.4, n_estimators=20)\n",
    "assert_equal(max_depth2, 6)\n",
    "assert_almost_equal(score2, 0.52450980392156865)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Curves\n",
    "\n",
    "Compute and display the validation curve for a Random Forest Classifier.\n",
    "Vary the `max_depth` parameter for the values in `param_range`. Plot the mean accuracy scores for the training set first, and then plot the mean accuracy scores for the cross validation data. Also, fill the range of plus/minus one standard deviation of the mean accuracy scores.\n",
    "\n",
    "Here is a sample plot:\n",
    "![](./images/vc.png)\n",
    "\n",
    "I've defined a `get_mean_and_stdev()` function that you may find helpful for this part of problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "f8e00e6368a7650ec0c09705330e4e39",
     "grade": false,
     "grade_id": "m_n_stdv",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Provided function; you don't need to do anything here.\n",
    "\n",
    "def get_mean_and_stdev(training_scores, testing_scores):\n",
    "    '''\n",
    "    Computes the means and standard deviations of the two input np.narrays.\n",
    "    Helpful for making validation curves.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    training_scores: A np.narray.\n",
    "    testing_scores: A np.narray.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A tuple of 4 np.narrays, in the order of: mean of first input array, stdev of first input array, \n",
    "                                              mean of second input array, stdev of second input array.\n",
    "    '''\n",
    "    \n",
    "    def mean_n_stdev(n):\n",
    "        return n.mean(axis=1), n.std(axis=1)\n",
    "    \n",
    "    trn_mean, trn_std = mean_n_stdev(training_scores)\n",
    "    tst_mean, tst_std = mean_n_stdev(testing_scores)\n",
    "    \n",
    "    return trn_mean, trn_std, tst_mean, tst_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "8f16bdf25413689add4ee3da22766062",
     "grade": false,
     "grade_id": "vc",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Problem starts here:\n",
    "\n",
    "def plot_validation_curve(X, y, random_state, param_range=np.arange(1,20), cv=5):\n",
    "    '''\n",
    "    Computes and displays the validation curve for Random Forest Classfier.\n",
    "    Plots the mean accuracy scores and fills the range of plus/minus \n",
    "    one standard deviation of the mean accuracy scores.\n",
    "    Note: you need to plot the training score curve first and then \n",
    "          the cross validation score curve to pass assertions.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X: A pandas.DataFrame. Classes.\n",
    "    y: A pandas.DataFrame. Features.\n",
    "    random_state: A RandomState instance. Used in RandomForestClassifier().\n",
    "    param_range: The values of the parameter that will be evaluated. Default: a list of ints from 1 to 20.\n",
    "    cv: An int. Cross-Validation generator. Default: 5.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A maplotlib.Axes instance.\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "5146f6ca6b92bef056ee4bfd22f4cdfa",
     "grade": false,
     "grade_id": "vc_plot",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "vc = plot_validation_curve(f_selected, c, check_random_state(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "b334095f657af975a84e6254536f14f4",
     "grade": true,
     "grade_id": "vc_test1",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_instance(vc, mpl.axes.Axes, msg=\"Your function should return a matplotlib.axes.Axes object.\")\n",
    "\n",
    "assert_equal(len(vc.lines), 2)\n",
    "\n",
    "assert_is_not(len(vc.title.get_text()), 0, msg=\"Your plot doesn't have a title.\")\n",
    "assert_is_not(vc.xaxis.get_label_text(), '', msg=\"Change the x-axis label to something more descriptive.\")\n",
    "assert_is_not(vc.yaxis.get_label_text(), '', msg=\"Change the y-axis label to something more descriptive.\")\n",
    "\n",
    "# check lines\n",
    "x_train, y_train = vc.lines[0].get_xydata().T\n",
    "assert_array_almost_equal(x_train, np.arange(1,20))\n",
    "assert_array_almost_equal(y_train, \n",
    "                          [ 0.22635556,  0.38835901,  0.54027221,  0.60997869,  0.71045737,\n",
    "                            0.7825216 ,  0.84086324,  0.91471541,  0.94298356,  0.9663274 ,\n",
    "                            0.9742014 ,  0.97935748,  0.97663546,  0.98165637,  0.99128017,\n",
    "                            0.98225592,  0.98481485,  0.98539211,  0.98220311])\n",
    "\n",
    "x_valid, y_valid = vc.lines[1].get_xydata().T\n",
    "assert_almost_equal(x_valid, np.arange(1,20))\n",
    "assert_array_almost_equal(y_valid, \n",
    "                        [ 0.19090551,  0.29747382,  0.41365137,  0.45535345,  0.48061187,\n",
    "                          0.50834061,  0.52570965,  0.5416222 ,  0.51355724,  0.52669318,\n",
    "                          0.54729495,  0.5429625 ,  0.52221434,  0.51364565,  0.56311908,\n",
    "                          0.53339753,  0.52099856,  0.52343397,  0.5232402 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "9efa6d3821189aea7a06b1a7b0dc952d",
     "grade": true,
     "grade_id": "vc_test2",
     "locked": true,
     "points": 6,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# check filled regions\n",
    "p_train, p_valid = vc.collections\n",
    "\n",
    "path_train = p_train.get_paths()[0].vertices\n",
    "assert_equal(len(path_train), 41)\n",
    "assert_array_almost_equal(path_train[:5], \n",
    "                          [[ 1.        ,  0.26823345],\n",
    "                           [ 1.        ,  0.18447767],\n",
    "                           [ 2.        ,  0.37238893],\n",
    "                           [ 3.        ,  0.51056177],\n",
    "                           [ 4.        ,  0.58950553]])\n",
    "assert_array_almost_equal(path_train[-5:], \n",
    "                          [[ 4.        ,  0.63045185],\n",
    "                           [ 3.        ,  0.56998265],\n",
    "                           [ 2.        ,  0.40432908],\n",
    "                           [ 1.        ,  0.26823345],\n",
    "                           [ 1.        ,  0.26823345]])\n",
    "\n",
    "path_valid = p_valid.get_paths()[0].vertices\n",
    "assert_equal(len(path_valid), 41)\n",
    "assert_array_almost_equal(path_valid[:5], \n",
    "                          [[ 1.        ,  0.23597253],\n",
    "                           [ 1.        ,  0.14583849],\n",
    "                           [ 2.        ,  0.26051277],\n",
    "                           [ 3.        ,  0.37502207],\n",
    "                           [ 4.        ,  0.41773231]])\n",
    "assert_array_almost_equal(path_valid[-5:],\n",
    "                         [[ 4.        ,  0.49297459],\n",
    "                          [ 3.        ,  0.45228068],\n",
    "                          [ 2.        ,  0.33443486],\n",
    "                          [ 1.        ,  0.23597253],\n",
    "                          [ 1.        ,  0.23597253]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
